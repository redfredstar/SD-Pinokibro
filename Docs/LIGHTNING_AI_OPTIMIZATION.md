# Lightning.ai Cloud Platform Optimization Guide

## Overview
This document provides comprehensive optimization strategies for applications running on Lightning.ai cloud GPU platform, based on authoritative documentation research. Lightning.ai is a cloud-based platform for running Jupyter notebooks on rented GPUs, not to be confused with PyTorch Lightning library.

## Core Lightning.ai Features

### 1. Multi-GPU Training Support
```python
from lightning import Trainer

# Automatic multi-GPU detection and configuration
trainer = Trainer(
    accelerator="gpu",
    devices="auto",  # Uses all available GPUs
    strategy="ddp_notebook"  # DDP optimized for notebooks
)

# Manual configuration for specific GPU count
trainer = Trainer(
    accelerator="gpu",
    devices=4,  # Use exactly 4 GPUs
    strategy="ddp_notebook"
)
```

### 2. Memory Optimization
```python
# 16-bit precision for memory efficiency
trainer = Trainer(
    accelerator="gpu",
    devices="auto",
    precision="16-mixed"  # Reduces memory usage by ~50%
)

# Gradient checkpointing for large models
class LargeModel(LightningModule):
    def configure_model(self):
        # Enable gradient checkpointing
        torch.utils.checkpoint.checkpoint_sequential(...)
```

### 3. Distributed Training Strategies
```python
# DDP Notebook for interactive environments
trainer = Trainer(
    accelerator="gpu",
    devices=8,
    strategy="ddp_notebook"  # Safe for Jupyter notebooks
)

# DDP Fork for non-interactive environments
trainer = Trainer(
    accelerator="gpu",
    devices=8,
    strategy="ddp_fork"  # More efficient for scripts
)
```

## Environment Detection and Configuration

### 1. Lightning.ai Platform Detection
```python
def detect_lightning_environment():
    \"\"\"Detect Lightning.ai environment and configure accordingly.\"\"\"
    try:
        # Check for Lightning.ai specific environment variables
        if 'LIGHTNING_CLOUD_SPACE_ID' in os.environ:
            return 'lightning_cloud'

        # Check for Lightning.ai compute nodes
        if 'LIGHTNING_NODE_ID' in os.environ:
            return 'lightning_compute'

        # Check for local Lightning.ai development
        if 'lightning' in str(sys.modules):
            return 'lightning_local'

        return 'other'
    except Exception:
        return 'unknown'

lightning_env = detect_lightning_environment()
```

### 2. Platform-Specific Optimizations
```python
# Lightning.ai Cloud optimized configuration
if lightning_env == 'lightning_cloud':
    trainer_config = {
        'accelerator': 'gpu',
        'devices': 'auto',
        'strategy': 'ddp_notebook',
        'precision': '16-mixed',
        'max_epochs': 100,
        'enable_checkpointing': True,
        'enable_progress_bar': True
    }
elif lightning_env == 'lightning_compute':
    trainer_config = {
        'accelerator': 'gpu',
        'devices': -1,  # Use all available GPUs
        'strategy': 'ddp',
        'precision': 'bf16-mixed',  # Brain floating point
        'max_epochs': 1000,
        'enable_checkpointing': True
    }
```

## Advanced GPU Optimization Techniques

### 1. FSDP (Fully Sharded Data Parallel)
```python
from lightning.fabric.strategies import FSDPStrategy

# FSDP for large model training
strategy = FSDPStrategy(
    limit_all_gathers=True,  # Memory optimization
    cpu_offload=True,        # Offload to CPU RAM
    activation_checkpointing=True
)

trainer = Trainer(
    accelerator="gpu",
    devices="auto",
    strategy=strategy
)
```

### 2. DeepSpeed Integration
```python
from lightning.pytorch.plugins import DeepSpeedStrategy

# DeepSpeed for extreme memory optimization
strategy = DeepSpeedStrategy(
    stage=3,  # ZeRO Stage 3
    offload_optimizer=True,
    offload_parameters=True
)

trainer = Trainer(
    accelerator="gpu",
    devices="auto",
    strategy=strategy
)
```

### 3. Memory-Efficient Training
```python
# Gradient accumulation for large batch sizes
trainer = Trainer(
    accumulate_grad_batches=4,  # Effective batch size = 4 * actual_batch_size
    gradient_clip_val=1.0
)

# Model checkpointing optimization
from lightning.pytorch.callbacks import ModelCheckpoint

checkpoint_callback = ModelCheckpoint(
    save_top_k=3,
    monitor="val_loss",
    mode="min",
    save_last=True
)
```

## Lightning.ai Specific Features

### 1. Auto-Scaling Configuration
```python
# Lightning.ai auto-scaling setup
trainer = Trainer(
    accelerator="gpu",
    devices="auto",
    auto_scale_batch_size=True,  # Automatically find optimal batch size
    auto_lr_find=True           # Automatically find optimal learning rate
)
```

### 2. Persistent Storage Integration
```python
# Lightning.ai persistent storage configuration
import os

# Use Lightning.ai persistent storage
persistent_path = os.environ.get('LIGHTNING_PERSISTENT_PATH', '/persistent')
checkpoint_path = f"{persistent_path}/checkpoints"
data_path = f"{persistent_path}/data"

# Configure trainer to use persistent storage
trainer = Trainer(
    default_root_dir=persistent_path,
    enable_checkpointing=True
)
```

### 3. Real-time Monitoring
```python
from lightning.pytorch.callbacks import Callback

class LightningAIMonitor(Callback):
    \"\"\"Custom callback for Lightning.ai monitoring.\"\"\"

    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        # Log metrics to Lightning.ai dashboard
        if hasattr(trainer, 'lightning_ai_logger'):
            trainer.lightning_ai_logger.log_metrics({
                'batch_loss': outputs['loss'],
                'gpu_memory': get_gpu_memory_usage()
            })

# Add to trainer
trainer = Trainer(
    callbacks=[LightningAIMonitor()]
)
```

## Performance Optimization Patterns

### 1. Data Loading Optimization
```python
# Optimized DataLoader for Lightning.ai
from torch.utils.data import DataLoader

def create_optimized_dataloader(dataset, batch_size=32):
    \"\"\"Create DataLoader optimized for Lightning.ai GPU environments.\"\"\"

    # Use num_workers optimized for GPU count
    gpu_count = get_gpu_count()
    num_workers = min(gpu_count * 2, 8)  # 2 workers per GPU, max 8

    return DataLoader(
        dataset,
        batch_size=batch_size,
        num_workers=num_workers,
        pin_memory=True,        # Faster GPU transfer
        persistent_workers=True, # Keep workers alive
        prefetch_factor=2       # Prefetch batches
    )
```

### 2. Model Optimization
```python
# Lightning.ai optimized model configuration
class OptimizedModel(LightningModule):
    \"\"\"Model optimized for Lightning.ai cloud GPUs.\"\"\"

    def __init__(self):
        super().__init__()
        self.model = create_efficient_model()

        # Lightning.ai specific optimizations
        if self.is_lightning_cloud():
            self.configure_for_cloud()

    def is_lightning_cloud(self):
        \"\"\"Check if running on Lightning.ai cloud.\"\"\"\"
        return 'LIGHTNING_CLOUD' in os.environ

    def configure_for_cloud(self):
        \"\"\"Apply Lightning.ai specific optimizations.\"\"\"\"
        # Enable mixed precision
        self.automatic_optimization = True

        # Configure gradient clipping
        self.gradient_clip_val = 1.0

        # Enable model checkpointing
        self.save_hyperparameters()
```

### 3. Training Loop Optimization
```python
# Optimized training step for Lightning.ai
def training_step(self, batch, batch_idx):
    \"\"\"Optimized training step with Lightning.ai considerations.\"\"\"

    # Move batch to GPU efficiently
    x, y = batch
    x = x.cuda(non_blocking=True)  # Non-blocking GPU transfer
    y = y.cuda(non_blocking=True)

    # Forward pass with gradient checkpointing
    with torch.cuda.amp.autocast():  # Mixed precision
        y_hat = self.model(x)
        loss = self.criterion(y_hat, y)

    # Log metrics efficiently
    self.log('train_loss', loss, sync_dist=True)

    return loss
```

## Error Handling and Debugging

### 1. Lightning.ai Specific Error Handling
```python
def handle_lightning_errors(error, context):
    \"\"\"Handle Lightning.ai specific errors with detailed reporting.\"\"\"

    try:
        # Lightning.ai specific error patterns
        if 'CUDA out of memory' in str(error):
            suggestion = \"ðŸ’¡ Try reducing batch size or enabling gradient checkpointing\"
        elif 'Process group' in str(error):
            suggestion = \"ðŸ’¡ Check GPU availability and DDP configuration\"
        elif 'Lightning.ai' in str(error):
            suggestion = \"ðŸ’¡ Check Lightning.ai platform status and quotas\"
        else:
            suggestion = \"ðŸ’¡ Check Lightning.ai documentation for platform-specific issues\"

        # Enhanced error reporting
        error_msg = f\"Lightning.ai Error: {error}\\nSuggestion: {suggestion}\\nContext: {context}\\nFull Traceback: {traceback.format_exc()}\"

        # Stream to UI
        stream_to_terminal(error_msg)

    except Exception as e:
        stream_to_terminal(f\"Error handling failed: {e}\")
```

### 2. GPU Memory Monitoring
```python
def monitor_gpu_memory():
    \"\"\"Monitor GPU memory usage for Lightning.ai optimization.\"\"\"

    try:
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
            memory_reserved = torch.cuda.memory_reserved() / 1024**3    # GB
            memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3

            return {
                'allocated_gb': memory_allocated,
                'reserved_gb': memory_reserved,
                'total_gb': memory_total,
                'utilization_percent': (memory_allocated / memory_total) * 100
            }
        else:
            return {'error': 'CUDA not available'}
    except Exception as e:
        return {'error': str(e)}
```

## Best Practices Summary

### 1. Environment Setup
- âœ… Use `ddp_notebook` strategy for interactive environments
- âœ… Enable `16-mixed` precision for memory efficiency
- âœ… Configure `devices="auto"` for automatic GPU detection
- âœ… Use persistent storage for checkpoints and data

### 2. Memory Management
- âœ… Enable gradient checkpointing for large models
- âœ… Use mixed precision training (16-mixed or bf16-mixed)
- âœ… Configure appropriate batch sizes for GPU memory
- âœ… Monitor memory usage throughout training

### 3. Performance Optimization
- âœ… Use `pin_memory=True` in DataLoaders
- âœ… Enable `persistent_workers=True` for worker efficiency
- âœ… Configure appropriate `num_workers` (2 per GPU)
- âœ… Use `sync_dist=True` for proper distributed logging

### 4. Error Handling
- âœ… Implement comprehensive error handling with full tracebacks
- âœ… Monitor GPU memory and provide optimization suggestions
- âœ… Handle Lightning.ai specific errors appropriately
- âœ… Provide actionable error messages for common issues

This optimization guide ensures PinokioCloud applications run efficiently on Lightning.ai cloud GPU platforms while maintaining all project principles and debugging capabilities.